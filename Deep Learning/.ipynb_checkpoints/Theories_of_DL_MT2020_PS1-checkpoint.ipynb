{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2Ea0Ks-g87k"
   },
   "source": [
    "# 1. Training Networks\n",
    "\n",
    "In this section we will build two Neural Networks, one from scratch, and one based on the high-level functions provided by Tensorflow.\n",
    "\n",
    "We will build a net from scratch to solve the XOR problem, and to do this we will rely on the backpropagation formulae that you have derived in the problem sheet.\n",
    "\n",
    "We will also build a network with Tensorflow to introduce you to their API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptfXqkaZiLMM"
   },
   "source": [
    "## 1.1 XOR problem - NN from Scratch\n",
    "\n",
    "In this problem we have four possible inputs with two possible outcomes; \n",
    "\n",
    " \n",
    "> $x_1 = 0, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=0$\n",
    "\n",
    "> $x_1 = 0, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=1$\n",
    "\n",
    "> $x_1 = 1, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=1$\n",
    "\n",
    "> $x_1 = 1, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=0$\n",
    "\n",
    "In the problem sheet you may have noticed that a two layer NN  could solve this problem exactly. Here we will see that on a 2-layer net with Sigmoid activation functions, with a random intialisation and the mean square loss, back-prop is able to converge to a pseudo-optimal solution. We will then consider a visualisation of how the neural network divides the input space as a classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4eQDGFI7b0"
   },
   "source": [
    "**Exercise** The class for the NeuralNet is already defined except for the backpropagation function, which you have to complete.\n",
    "\n",
    "Note: Once you have implemented backprop, if you get poor performance, try running the cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "ZBiFs8xZGNlM",
    "outputId": "fb35d6f1-8b22-4fc4-dad7-a2d28e54473b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " [[0]\n",
      " [0]]  ---> [[0.02951077]]\n",
      "Prediction:\n",
      " [[0]\n",
      " [1]]  ---> [[0.97394909]]\n",
      "Prediction:\n",
      " [[1]\n",
      " [0]]  ---> [[0.97395787]]\n",
      "Prediction:\n",
      " [[1]\n",
      " [1]]  ---> [[0.02738388]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "    \n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x)) # What the fuck? x * (1 - x)???\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        dimension = 2\n",
    "        self.input        = x\n",
    "        self.weights1     = np.random.rand(dimension, x.shape[1])      #np.array([[-1,1],[1,-1]], dtype=np.float) #\n",
    "        self.weights2     = np.random.rand(1,dimension)      \n",
    "        self.bias1        = np.random.rand(dimension,1)      #0.5*np.ones((dimension,1)) # np.random.rand(dimension,1)      #\n",
    "        self.bias2        = np.random.rand(1,1)           \n",
    "        self.y            = y\n",
    "        self.output       = np.zeros(self.y.shape)\n",
    "        self.activation   = sigmoid\n",
    "        self.d_activation = sigmoid_derivative\n",
    "\n",
    "    def feedforward(self,x):\n",
    "        self.x = np.expand_dims(x,axis =1)\n",
    "        \n",
    "        self.z1 = self.weights1 @  self.x + self.bias1\n",
    "        self.layer1 = self.activation(self.z1)\n",
    "                \n",
    "        self.z2 = self.weights2 @ self.layer1 + self.bias2\n",
    "        self.output = self.activation(self.z2)\n",
    "\n",
    "    def call(self,x):\n",
    "        x = np.expand_dims(x,axis =1)\n",
    "        layer1 = self.activation(self.weights1 @  x + self.bias1)\n",
    "        output = self.activation(self.weights2 @ layer1 + self.bias2)\n",
    "        return output\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights1 = np.zeros(self.weights1.shape)\n",
    "        d_weights2 = np.zeros(self.weights2.shape)\n",
    "        d_bias1    = np.zeros(self.bias1.shape)\n",
    "        d_bias2    = np.zeros(self.bias2.shape)\n",
    "        lr = 1\n",
    "        for j in range(4):\n",
    "          # compute gradient per each input image\n",
    "          single_input = self.input[j]\n",
    "          # single_y = np.expand_dims(self.y[j], axis = 1)\n",
    "          self.feedforward(single_input)\n",
    "          d_loss = (self.output - self.y[j])/4\n",
    "\n",
    "          self.delta2 = d_loss @ sigmoid_derivative(self.z2)\n",
    "          d_bias2    += self.delta2\n",
    "\n",
    "          d_weights2 += self.delta2 @ self.layer1.T\n",
    "          \n",
    "          self.delta1 = (self.weights2.T @(self.delta2)) * sigmoid_derivative(self.z1)\n",
    "          d_weights1 += self.delta1.dot(self.x.T) # self.delta2.dot(self.layer1.T)\n",
    "          d_bias1    += self.delta1\n",
    "\n",
    "        self.weights1 -= d_weights1 * lr\n",
    "        self.weights2 -= d_weights2 * lr\n",
    "        self.bias1    -= d_bias1 * lr\n",
    "        self.bias2    -= d_bias2 * lr\n",
    "\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "nn = NeuralNetwork(X,y)\n",
    "\n",
    "for i in range(10000):\n",
    "    nn.backprop()\n",
    "for j in range(4):\n",
    "    nn.feedforward(X[j])\n",
    "    print('Prediction:\\n', nn.x, ' --->' , nn.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ncvIv2vepg6"
   },
   "source": [
    "Now we will plot how the domain has been split. In the left figure we will see the outputs of the NN, while on the right we visualise the classification of these outputs i.e. any value above 0.5 identifies class 1, 0 otherwise, which shows us the decision boundary of the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "jI1Tv1mAeyl9",
    "outputId": "415e506e-c410-46c6-a1d2-c36124571939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f84d881b7f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "mu = np.linspace(0,1,100)\n",
    "gamma = np.linspace(0,1,100)\n",
    "\n",
    "# filling the heatmap, value by value\n",
    "fun_map = np.empty((mu.size, gamma.size))\n",
    "for i in range(mu.size):\n",
    "    for j in range(gamma.size):\n",
    "        net_val = nn.call([mu[i], gamma[j]])\n",
    "        if net_val>0.5:\n",
    "          fun_map[i,j] = 1\n",
    "        else:\n",
    "          fun_map[i,j] = 0\n",
    "\n",
    "fun_map_2 = np.empty((mu.size, gamma.size))\n",
    "for i in range(mu.size):\n",
    "    for j in range(gamma.size):\n",
    "        fun_map_2[i,j] = nn.call([mu[i], gamma[j]])\n",
    "\n",
    "fig = plt.figure()\n",
    "s = fig.add_subplot(1, 2, 1, xlabel='$x$', ylabel='$y$')\n",
    "im = s.imshow(\n",
    "    fun_map_2,\n",
    "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
    "    origin='lower')\n",
    "fig.colorbar(im)\n",
    "s = fig.add_subplot(1, 2, 2, xlabel='$x$', ylabel='$y$')\n",
    "im = s.imshow(\n",
    "    fun_map,\n",
    "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
    "    origin='lower')\n",
    "fig.colorbar(im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzDVeZloHFwy"
   },
   "source": [
    "N.B. The transition fase with the sigmoid activation function is sharp, and so the NN more-or-less splits the domain into piecwise constant regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIrwTlPU7iVe"
   },
   "source": [
    "## 1.2 Training MNIST\n",
    "\n",
    "First, we have to upload the dataset; keras, an interface for tensorflow, allows us to do this with a one line command. We then can use the Sequence model class from TF to add different layers to our network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "MJpPyFJyDXC9",
    "outputId": "c4cce974-1e81-403d-b0bf-90fa56ef4a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels)= mnist.load_data()\n",
    "\n",
    "print(train_images.shape) # Check if images are loaded correctly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i6TvhuW842p"
   },
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9c213Z3MfrD"
   },
   "source": [
    "**Exercise** You now have to generate a two layer network with hidden dimension of 128 via the sequential command in Tensorflow. This should allow you to achieve 92% accuracy with only15 epochs of training!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qO2O_0T7MiHb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Generate data\n",
    "x_train = train_images\n",
    "y_train = train_labels\n",
    "\n",
    "x_test = test_images\n",
    "y_test = test_labels\n",
    "\n",
    "# build the architecture with Sequential\n",
    "# ...\n",
    "model = Sequential([Flatten(input_shape = (28, 28)),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    # Dense(64, activation='relu'),\n",
    "                    # Dense(64, activation='relu'),\n",
    "                    Dense(10, activation='softmax'),])\n",
    "\n",
    "# Compile the model, which involved shoows a loss function, an optimiser, and the performance metrics you want to track\n",
    "# ...\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "oo_UWLK0646i",
    "outputId": "cb9c2e72-659a-485a-8485-f4f224d9c25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "ZVt3HV5hM_bJ",
    "outputId": "893f9117-cf28-43bf-c9b4-f60b53d2da7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 2s 896us/step - loss: 2.4151 - accuracy: 0.8579\n",
      "Epoch 2/15\n",
      "1792/1875 [===========================>..] - ETA: 0s - loss: 0.3742 - accuracy: 0.9107"
     ]
    }
   ],
   "source": [
    "# train the architecture\n",
    "#...\n",
    "model.fit(x_train, y_train, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "IdgtcleFNDI9",
    "outputId": "d8b8732e-9970-484d-df19-d395d62a87aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 650us/step - loss: 0.3422 - accuracy: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3421567976474762, 0.9465000033378601]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the performance\n",
    "# ...\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbdIpyUpNxec"
   },
   "source": [
    "# 2. Expressivity\n",
    "\n",
    "The **$n$-ap problem** was shown to have an optimal solution with a particular construction of neural network. Do we find these coefficients/weights when training a network with that structure from randomly inittialised weights?\n",
    "\n",
    "**Exercise** Build the net in the case with $n=2^K, K=3$ and check if it converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hxwKrnWmPzrG",
    "outputId": "1480d1f1-078d-4779-a95d-15563ecae594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.6250\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.6250\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.6250\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6250\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6250\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.6250\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.6250\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.6250\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.6250\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6250\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.6250\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.6250\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.6250\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6250\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6250\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.6250\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.6250\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6250\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6250\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6250\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.6250\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.6250\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6250\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6250\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6250\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6250\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.6250\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6250\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.6250\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.6250\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6250\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.6250\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6250\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6250\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.6250\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6250\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6250\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.6250\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6250\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6250\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6250\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.6250\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.6250\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.6250\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.6250\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6250\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6250\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6250\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6250\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.6250\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6250\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6250\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.6250\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.6250\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6250\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.6250\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.6250\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.6250\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6250\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.6250\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6250\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.6250\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6250\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6250\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.6250\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.6250\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6250\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6250\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.6250\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6250\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6250\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6250\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.6250\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6250\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.6250\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6250\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6250\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.6250\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6250\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.6250\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6250\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6250\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.6250\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.6250\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.6250\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6250\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6250\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.6250\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.6250\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.6250\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.6250\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.6250\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6250\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.6250\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6250\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.6250\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6250\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6250\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.6250\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6250\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.6250\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.6250\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.6250\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.6250\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6756 - accuracy: 0.6250\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.6250\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6250\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.6250\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.6250\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.6250\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6250\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6250\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6250\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6250\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.6250\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6746 - accuracy: 0.6250\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.6250\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6743 - accuracy: 0.6250\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.6250\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6250\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6250\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.6250\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.6250\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.6250\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6250\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6250\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.6250\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6735 - accuracy: 0.6250\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6250\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6250\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6732 - accuracy: 0.6250\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6250\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6250\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6250\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6250\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6250\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.6250\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.6250\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6726 - accuracy: 0.6250\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6250\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6250\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6250\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6250\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6250\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6250\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.6250\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6250\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6250\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6250\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.6250\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6250\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6250\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.6250\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6250\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6250\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.6250\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6250\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6250\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.6250\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6250\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.6250\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6250\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.6250\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6250\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6250\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6250\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6250\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6250\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.6250\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6703 - accuracy: 0.6250\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.6250\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.6250\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6250\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6250\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6250\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6250\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6250\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6250\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.6250\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6697 - accuracy: 0.6250\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.6250\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6695 - accuracy: 0.6250\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.6250\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.6250\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6250\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6250\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.6250\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.6250\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6690 - accuracy: 0.6250\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.6250\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.6250\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6250\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6250\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.6250\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6250\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.6250\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6250\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6250\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6250\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6250\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6250\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.6250\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6250\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6250\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6250\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6250\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6250\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6250\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6250\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.6250\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6250\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.6250\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6250\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6250\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6250\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6250\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6250\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6250\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6250\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6250\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6250\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.6250\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6250\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.6250\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6250\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.6250\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6250\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.6250\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6250\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6250\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6663 - accuracy: 0.6250\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6250\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6250\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6250\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6250\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6250\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.6250\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6658 - accuracy: 0.6250\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6250\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6250\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6250\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.6250\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6250\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6250\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.6250\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.6250\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.6250\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.6250\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.6250\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6250\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6250\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.6250\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6250\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6250\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6250\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6250\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6250\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6250\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.6250\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6250\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.6250\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6250\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6250\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6250\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6250\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6250\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6250\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6250\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6250\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6250\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6250\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.6250\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6250\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6250\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6250\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6250\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6250\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6250\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6250\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6250\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6250\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6250\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6250\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6250\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6250\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6625 - accuracy: 0.6250\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6250\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6250\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6623 - accuracy: 0.6250\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.6250\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6250\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6250\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6250\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.6250\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6250\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6250\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6250\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6250\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6250\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6250\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6250\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6250\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6250\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6250\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6250\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6250\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6250\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6250\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6250\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6250\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6250\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6250\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6250\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6250\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6250\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6250\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6250\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6250\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6250\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6250\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6250\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6250\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6250\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6250\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6250\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6250\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6250\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6250\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6250\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6250\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6250\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6595 - accuracy: 0.6250\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6250\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6250\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6250\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6250\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6250\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6250\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6250\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6250\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6250\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6250\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6250\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.6250\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6250\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6250\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6250\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6250\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6250\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6250\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6250\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6250\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.6581 - accuracy: 0.6250\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6250\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6250\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6250\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6250\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6250\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6250\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6250\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6250\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6250\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6250\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6250\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6250\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6250\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6250\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6250\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 928us/step - loss: 0.6568 - accuracy: 0.6250\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6250\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6250\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6565 - accuracy: 0.6250\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6250\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6250\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6250\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6250\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6250\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6250\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6250\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6250\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6250\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6250\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6250\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6250\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6250\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6250\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6250\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6250\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6250\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6250\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6250\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6250\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6250\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6250\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6250\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6250\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6250\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6250\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6250\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6250\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6250\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.6250\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6250\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6250\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6250\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6538 - accuracy: 0.6250\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6250\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6250\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6536 - accuracy: 0.6250\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6250\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6250\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6250\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6250\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6250\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6250\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6250\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6250\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6250\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6250\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6250\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6250\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6250\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6250\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6250\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6250\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6250\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6250\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6250\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6250\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6250\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6250\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6250\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6250\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6250\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6250\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6250\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6250\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6250\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6250\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6250\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6250\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.6250\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6250\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6250\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6250\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6250\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6250\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6250\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6250\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6250\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6250\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6250\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6250\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6250\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6250\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6250\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6250\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6250\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6250\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.6250\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6250\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6250\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6250\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6250\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6250\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6250\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6250\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6250\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6250\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6250\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6250\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6250\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6250\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6250\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6250\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6250\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6250\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6250\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6250\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6250\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6250\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6250\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6250\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6250\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6250\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6250\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6250\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6250\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6250\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6250\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6250\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.6250\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6250\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6250\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.6250\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6448 - accuracy: 0.6250\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6250\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6250\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.6250\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6250\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6250\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6250\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.6250\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6250\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6250\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6250\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6250\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6250\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6250\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6250\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.6250\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6250\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6250\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6250\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6250\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6250\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6250\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6250\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6250\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6250\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6250\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6250\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6250\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6250\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.6250\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6250\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6250\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6250\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6250\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6250\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6250\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6250\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6250\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6250\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6250\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6250\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6250\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6250\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6250\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6250\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6250\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6250\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6250\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6250\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6250\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6250\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6250\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6250\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6250\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6250\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6250\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6250\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6250\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6250\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6250\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6250\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6250\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6250\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6250\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6250\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.6250\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.6250\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6250\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6250\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6250\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6250\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6250\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6250\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6250\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6250\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6250\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6250\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6250\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6250\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6250\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6250\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6250\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6250\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6250\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.5000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.5000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.5000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.5000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.5000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.5000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.5000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.5000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.5000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.5000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.5000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.5000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.5000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.5000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.5000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.5000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.5000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.5000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.5000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.5000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.5000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.5000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.5000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.5000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.5000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6250\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6250\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6250\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6250\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6250\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6267 - accuracy: 0.6250\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6250\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6250\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6250\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6250\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6250\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6250\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6250\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6250\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6250\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6250\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6250\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6250\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.6250\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6250\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6250\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.6250\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.6250\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6250\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6250\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6250\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6250\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6250\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6250\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6250\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6250\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6250\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6250\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6250\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6250\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6250\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6250\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6250\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6250\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6250\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6250\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6250\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6250\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6250\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6250\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6250\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.6250\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6250\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6250\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6250\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6250\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.6250\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6250\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 952us/step - loss: 0.6199 - accuracy: 0.6250\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6250\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6250\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.6196 - accuracy: 0.6250\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6250\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 971us/step - loss: 0.6196 - accuracy: 0.6250\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6193 - accuracy: 0.6250\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6250\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6250\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6250\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 950us/step - loss: 0.6188 - accuracy: 0.6250\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6250\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6250\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.6250\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6250\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6250\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 941us/step - loss: 0.6182 - accuracy: 0.6250\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6250\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6250\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.6250\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6250\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6250\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6250\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6250\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 892us/step - loss: 0.6174 - accuracy: 0.6250\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.6175 - accuracy: 0.6250\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6250\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6250\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6250\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6250\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6250\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6250\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6250\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6250\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6250\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6250\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.6250\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.6250\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6250\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6250\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6250\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6250\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6250\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6250\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6250\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6250\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6250\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6250\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6250\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6250\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6250\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6250\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6250\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6250\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6250\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6250\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6250\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6250\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6250\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6250\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6250\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6140 - accuracy: 0.6250\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.6250\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6250\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6137 - accuracy: 0.6250\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6250\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6135 - accuracy: 0.6250\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6250\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.6250\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6250\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6135 - accuracy: 0.6250\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6250\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6250\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6250\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6250\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6250\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.6250\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.6250\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6250\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.6250\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6250\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6250\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6250\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6250\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6250\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.6250\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6250\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6250\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.6250\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.6250\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6118 - accuracy: 0.6250\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6250\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6250\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6250\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6250\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6112 - accuracy: 0.6250\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 879us/step - loss: 0.6112 - accuracy: 0.6250\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6250\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6250\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6250\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6250\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6108 - accuracy: 0.6250\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6250\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6250\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6250\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6250\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6250\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6250\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6250\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6250\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6250\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6250\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6250\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6250\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6250\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6101 - accuracy: 0.6250\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.6250\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6250\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.6250\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6250\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.6250\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6250\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 909us/step - loss: 0.6093 - accuracy: 0.6250\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6250\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6250\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6250\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6250\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6250\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6250\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.6250\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.6250\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6087 - accuracy: 0.6250\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6250\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6250\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6250\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6083 - accuracy: 0.6250\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6250\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6250\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6250\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6250\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6250\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6250\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6250\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.6250\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.6250\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6250\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6250\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.6250\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6250\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6250\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6250\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.6250\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6250\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6250\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6250\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6250\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6250\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6250\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6069 - accuracy: 0.6250\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.6250\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6250\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6250\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6250\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6250\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6250\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6250\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6250\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6250\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6250\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6250\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6250\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6250\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6250\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6250\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.6250\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.6250\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6250\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6250\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.6250\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6250\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6056 - accuracy: 0.6250\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.6250\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6250\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6055 - accuracy: 0.6250\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.6250\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6053 - accuracy: 0.6250\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6052 - accuracy: 0.6250\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6250\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6250\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.6250\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6250\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6250\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6250\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6250\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6250\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6250\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6250\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6250\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6250\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6250\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6250\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6250\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6250\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6250\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6250\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6250\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6250\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6250\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6250\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.6038 - accuracy: 0.6250\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 863us/step - loss: 0.6038 - accuracy: 0.6250\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6250\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.6250\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6250\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6250\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6250\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.6250\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6250\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6036 - accuracy: 0.6250\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6250\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 918us/step - loss: 0.6035 - accuracy: 0.6250\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6250\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 906us/step - loss: 0.6036 - accuracy: 0.6250\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 937us/step - loss: 0.6033 - accuracy: 0.6250\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.6034 - accuracy: 0.6250\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6250\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6250\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6250\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6250\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.6250\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6250\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6250\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.6250\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6250\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6250\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6250\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.6250\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6250\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6250\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6250\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6250\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6250\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6250\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6250\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6250\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6250\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6250\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6250\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6250\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6250\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6250\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.6250\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6020 - accuracy: 0.6250\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6250\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6250\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6250\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6250\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6250\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6250\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6250\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6250\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.6250\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6250\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6250\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6250\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.6250\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.6250\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6250\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6250\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6250\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6250\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6250\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6250\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6250\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6250\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6250\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6006 - accuracy: 0.6250\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6250\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6004 - accuracy: 0.6250\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6250\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6250\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6002 - accuracy: 0.6250\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6250\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6250\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6000 - accuracy: 0.6250\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.6250\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.6250\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 922us/step - loss: 0.5998 - accuracy: 0.6250\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.6250\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.6250\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6250\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6250\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6250\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6250\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6250\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6250\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6250\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6250\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6250\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6250\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6250\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6250\n",
      "\n",
      "accuracy: 62.50%\n",
      "WARNING:tensorflow:From <ipython-input-2-3f9b97371489>:39: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Y=[0], Predicted=[0]\n",
      "Y=[1], Predicted=[1]\n",
      "Y=[0], Predicted=[1]\n",
      "Y=[1], Predicted=[1]\n",
      "Y=[0], Predicted=[1]\n",
      "Y=[1], Predicted=[1]\n",
      "Y=[0], Predicted=[1]\n",
      "Y=[1], Predicted=[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate data\n",
    "X = np.array([[0],\n",
    "                  [.125],\n",
    "                  [.25],\n",
    "                  [.375],\n",
    "                  [.5],\n",
    "                  [.625],\n",
    "                  [.75],\n",
    "                  [.875]])\n",
    "y = np.array([[0],[1],[0],[1],[0],[1],[0],[1]])\n",
    "x_train = X\n",
    "y_train = y\n",
    "\n",
    "# Build a model\n",
    "# ...\n",
    "model = Sequential([Dense(6, activation = 'relu'),\n",
    "                    Dense(6, activation = 'relu'),\n",
    "                    Dense(6, activation = 'relu'),\n",
    "                    Dense(6, activation = 'relu'),\n",
    "                    Dense(6, activation = 'relu'),\n",
    "                    Dense(6, activation = 'relu'),\n",
    "\n",
    "                    # Dense(2, activation = 'relu'),\n",
    "                    # Dense(2, activation = 'relu'),\n",
    "                    # Dense(2, activation = 'relu'),\n",
    "                    # Dense(2, activation = 'relu'),\n",
    "                    # Dense(2, activation = 'relu'),\n",
    "                    Dense(1, activation = 'sigmoid')])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# ...\n",
    "model.fit(x_train, y_train, epochs = 1000)\n",
    "\n",
    "scores = model.evaluate(X, y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "ynew = model.predict_classes(x_train)\n",
    "for i in range(len(x_train)):\n",
    "\tprint(\"Y=%s, Predicted=%s\" % (y_train[i], ynew[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "dQ0e-YqVRAvK",
    "outputId": "44393a05-5e28-441f-bf9d-851fd734fd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_179 (Dense)            (None, 1000)              2000      \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 2)                 2002      \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 4,035\n",
      "Trainable params: 4,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zVbcSsha9xQ"
   },
   "source": [
    "And now let's plot the modelled function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "T5V40mAne235",
    "outputId": "6200e6ff-89ce-4b3d-9870-84ccf40e1958"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model(nn,x,y):\n",
    "  xx = np.linspace(0,1,10000)\n",
    "  yy = nn.predict(xx)\n",
    "  fig = plt.figure()\n",
    "  plt.plot(xx,yy)\n",
    "  plt.plot(x,y, 'rx')\n",
    "  \n",
    "plot_model(model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZLf8oyURRrA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Theories_of_DL_MT2020_PS1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
